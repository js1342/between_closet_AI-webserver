{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 색 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22275"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import pycocotools.mask as mask\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "image_paths = glob(os.path.join('data', 'cropped_color_image_add','*.jpg'))\n",
    "image_paths.sort()\n",
    "\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_paths)):\n",
    "    filename = image_paths[i].split('/')[-1]\n",
    "    original_image = cv2.imread('./data/cropped_color_image_add/' + filename)\n",
    "    resizeHeight = int(600)\n",
    "    resizeWidth  = int(600)\n",
    "    resized_image = cv2.resize(original_image, (resizeHeight, resizeWidth), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imwrite('./data/cropped_color_image_resize/' + filename, resized_image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 패키지 import 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os.path as pth\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Activation , AveragePooling2D , Input ,Dropout\n",
    "from tensorflow.keras.layers import Dense,  MaxPooling2D, Add, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 특정 GPU에 제한된 메모리만 할당\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=13000)])\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "        print(e)\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "color_mapping = {'갈색' : 0, '검정색' : 1, '노란색' : 2, '보라색' : 3, '분홍색' : 4, \n",
    "                 '빨간색' : 5, '초록색' : 6, '파란색' : 7, '회색' : 8, '흰색' : 9}\n",
    "\n",
    "train_data = pd.read_csv('./data/cropped_color_add.csv')\n",
    "colors = train_data['color'].unique()\n",
    "colors.sort()\n",
    "\n",
    "values = []\n",
    "for i in range(10):\n",
    "    values.append(sum(train_data['color']==i))\n",
    "    \n",
    "x = np.arange(10)\n",
    "\n",
    "plt.bar(x, values)\n",
    "plt.xticks(x, colors)\n",
    "plt.show()\n",
    "\n",
    "# color_mapping = {'갈색' : 0, '검정색' : 1, '노란색' : 2, '보라색' : 3, '분홍색' : 4, \n",
    "#                  '빨간색' : 5, '초록색' : 6, '파란색' : 7, '회색' : 8, '흰색' : 9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 변환 및 TFrecod 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    train_data['file_name'][i] = str(train_data['file_name'][i]) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22270</th>\n",
       "      <td>9991.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22271</th>\n",
       "      <td>9993.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22272</th>\n",
       "      <td>9995.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22273</th>\n",
       "      <td>9998.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22274</th>\n",
       "      <td>9999.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  color\n",
       "0          1.jpg      1\n",
       "1         10.jpg      1\n",
       "2       1000.jpg      1\n",
       "3      10000.jpg      4\n",
       "4      10001.jpg      4\n",
       "...          ...    ...\n",
       "22270   9991.jpg      4\n",
       "22271   9993.jpg      4\n",
       "22272   9995.jpg      4\n",
       "22273   9998.jpg      4\n",
       "22274   9999.jpg      4\n",
       "\n",
       "[22275 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/cropped_color_image_resize/'\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _floatarray_feature(array):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=array))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _validate_text(text):\n",
    "    \"\"\"If text is not str or unicode, then try to convert it to str.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text\n",
    "    elif isinstance(text, 'unicode'):\n",
    "        return text.encode('utf8', 'ignore')\n",
    "    else:\n",
    "        return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tfrecords(id_list, color_id_list, tfrecords_name):\n",
    "    print(\"Start converting\")\n",
    "    options = tf.io.TFRecordOptions(compression_type = 'GZIP')\n",
    "    with tf.io.TFRecordWriter(path=pth.join(tfrecords_name+'.tfrecords'), options=options) as writer:\n",
    "        for id_, color_id in tqdm(zip(id_list, color_id_list), total=len(id_list), position=0, leave=True):\n",
    "            image_path = pth.join(path, id_)\n",
    "            _binary_image = tf.io.read_file(image_path)\n",
    "            \n",
    "            string_set = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image_raw': _bytes_feature(_binary_image),\n",
    "                'color_id': _int64_feature(color_id),\n",
    "                'id': _bytes_feature(id_.encode()),\n",
    "            }))\n",
    "\n",
    "            writer.write(string_set.SerializeToString())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/20047 [00:00<00:52, 384.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start converting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20047/20047 [00:55<00:00, 364.47it/s]\n",
      "  2%|▏         | 37/2228 [00:00<00:06, 353.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start converting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2228/2228 [00:06<00:00, 361.49it/s]\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    train_ids, val_ids, train_color_ids, val_color_ids = train_test_split(train_data['file_name'], train_data['color'], test_size=0.1, random_state=42, shuffle=True,\n",
    "                                                                                stratify=train_data['color'])\n",
    "\n",
    "    to_tfrecords(train_ids, train_color_ids, pth.join(path, 'tf_record_train'))\n",
    "    to_tfrecords(val_ids, val_color_ids, pth.join(path, 'tf_record_valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_test_tfrecords(id_list, test_id_list, tfrecords_name):\n",
    "    print(\"Start converting\")\n",
    "    options = tf.io.TFRecordOptions(compression_type = 'GZIP')\n",
    "    with tf.io.TFRecordWriter(path=pth.join(tfrecords_name+'.tfrecords'), options=options) as writer:\n",
    "        for id_, test_id in tqdm(zip(id_list, test_id_list), total=len(id_list), position=0, leave=True):\n",
    "            image_path = id_\n",
    "            _binary_image = tf.io.read_file(image_path)\n",
    "\n",
    "            string_set = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image_raw': _bytes_feature(_binary_image),\n",
    "                'id': _bytes_feature(test_id.encode()),\n",
    "            }))\n",
    "\n",
    "            writer.write(string_set.SerializeToString())    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    to_test_tfrecords(test_data['file_name'],test_data['color'], pth.join(path, 'tf_record_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test는 추후 수정\n",
    "\n",
    "# def to_test_tfrecords(id_list, test_id_list, tfrecords_name):\n",
    "#     print(\"Start converting\")\n",
    "#     options = tf.io.TFRecordOptions(compression_type = 'GZIP')\n",
    "#     with tf.io.TFRecordWriter(path=pth.join(tfrecords_name+'.tfrecords'), options=options) as writer:\n",
    "#         for id_, test_id in tqdm(zip(id_list, test_id_list), total=len(id_list), position=0, leave=True):\n",
    "#             image_path = id_\n",
    "#             _binary_image = tf.io.read_file(image_path)\n",
    "\n",
    "#             string_set = tf.train.Example(features=tf.train.Features(feature={\n",
    "#                 'image_raw': _bytes_feature(_binary_image),\n",
    "#                 'id': _bytes_feature(test_id.encode()),\n",
    "#             }))\n",
    "\n",
    "#             writer.write(string_set.SerializeToString())    \n",
    "\n",
    "# with tf.device('/device:GPU:1'):\n",
    "#     test_ids = test_data['id']\n",
    "#     to_test_tfrecords(test_data['file'],test_data['id'], pth.join(path, 'tf_record_test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFrecord 읽어 들이기, Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecord_path = pth.join(path, 'tf_record_train.tfrecords')\n",
    "valid_tfrecord_path = pth.join(path, 'tf_record_valid.tfrecords')\n",
    "\n",
    "BUFFER_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    image_feature_description = {\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'color_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "        # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = target_record['color_id']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def prep_func(image, label):\n",
    "    result_image = image / 255\n",
    "    result_image = tf.image.resize(result_image, (600,600))\n",
    "    result_image = tf.image.central_crop(result_image, 0.5)\n",
    "#     result_image = tf.image.random_brightness(result_image, 0.2)\n",
    "    onehot_label = tf.one_hot(label, depth=NUM_CLASS)\n",
    "    return result_image, onehot_label\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    dataset = tf.data.TFRecordDataset(train_tfrecord_path, compression_type='GZIP')\n",
    "    dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    valid_dataset = tf.data.TFRecordDataset(valid_tfrecord_path, compression_type='GZIP')\n",
    "    valid_dataset = valid_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    valid_dataset = valid_dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "    valid_dataset = valid_dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    valid_dataset = valid_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 153, 113, 32)      6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 153, 113, 32)      128       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 76, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 52, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 72, 52, 64)        256       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 36, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 34, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 17, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 26112)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               13369856  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 13,671,146\n",
      "Trainable params: 13,668,906\n",
      "Non-trainable params: 2,240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (8, 8), strides=(1, 1), activation='relu', input_shape=(160, 120, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), strides=(1, 1), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction=ReduceLROnPlateau(\n",
    "                        monitor= \"val_loss\", \n",
    "                        patience = 2, \n",
    "                        factor = 0.8, \n",
    "                        min_lr=0.0001,\n",
    "                        verbose=1)\n",
    "model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장\n",
    "        filepath=\"clothes_color_base_CNN_model.h5\", #모델 파일 경로\n",
    "        monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "        save_best_only=True)\n",
    "\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.00005),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "627/627 [==============================] - 23s 37ms/step - loss: 1.4161 - categorical_accuracy: 0.5720 - val_loss: 1.2644 - val_categorical_accuracy: 0.6158\n",
      "Epoch 2/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 1.3746 - categorical_accuracy: 0.5845 - val_loss: 1.9323 - val_categorical_accuracy: 0.4484\n",
      "Epoch 3/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.3462 - categorical_accuracy: 0.5879 - val_loss: 1.2106 - val_categorical_accuracy: 0.6252\n",
      "Epoch 4/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 1.3293 - categorical_accuracy: 0.5972 - val_loss: 1.2547 - val_categorical_accuracy: 0.5983\n",
      "Epoch 5/100\n",
      "627/627 [==============================] - 24s 38ms/step - loss: 1.3017 - categorical_accuracy: 0.6016 - val_loss: 1.2839 - val_categorical_accuracy: 0.5934\n",
      "Epoch 6/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.2924 - categorical_accuracy: 0.6066 - val_loss: 1.1613 - val_categorical_accuracy: 0.6302\n",
      "Epoch 7/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.2726 - categorical_accuracy: 0.6083 - val_loss: 1.1733 - val_categorical_accuracy: 0.6266\n",
      "Epoch 8/100\n",
      "627/627 [==============================] - 23s 37ms/step - loss: 1.2656 - categorical_accuracy: 0.6127 - val_loss: 1.3667 - val_categorical_accuracy: 0.5337\n",
      "Epoch 9/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.2465 - categorical_accuracy: 0.6171 - val_loss: 1.1913 - val_categorical_accuracy: 0.6207\n",
      "Epoch 10/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 1.2393 - categorical_accuracy: 0.6207 - val_loss: 1.2454 - val_categorical_accuracy: 0.5839\n",
      "Epoch 11/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.2211 - categorical_accuracy: 0.6229 - val_loss: 1.2405 - val_categorical_accuracy: 0.5974\n",
      "Epoch 12/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.2210 - categorical_accuracy: 0.6266 - val_loss: 1.2573 - val_categorical_accuracy: 0.6055\n",
      "Epoch 13/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.2055 - categorical_accuracy: 0.6280 - val_loss: 1.1701 - val_categorical_accuracy: 0.6216\n",
      "Epoch 14/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 1.2023 - categorical_accuracy: 0.6278 - val_loss: 1.1656 - val_categorical_accuracy: 0.6279\n",
      "Epoch 15/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.1839 - categorical_accuracy: 0.6352 - val_loss: 1.1300 - val_categorical_accuracy: 0.6346\n",
      "Epoch 16/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.1833 - categorical_accuracy: 0.6352 - val_loss: 1.1776 - val_categorical_accuracy: 0.6140\n",
      "Epoch 17/100\n",
      "627/627 [==============================] - 25s 39ms/step - loss: 1.1759 - categorical_accuracy: 0.6355 - val_loss: 1.1544 - val_categorical_accuracy: 0.6203\n",
      "Epoch 18/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.1648 - categorical_accuracy: 0.6410 - val_loss: 1.2322 - val_categorical_accuracy: 0.6005\n",
      "Epoch 19/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.1561 - categorical_accuracy: 0.6437 - val_loss: 1.1044 - val_categorical_accuracy: 0.6472\n",
      "Epoch 20/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.1508 - categorical_accuracy: 0.6449 - val_loss: 1.1353 - val_categorical_accuracy: 0.6355\n",
      "Epoch 21/100\n",
      "627/627 [==============================] - 23s 37ms/step - loss: 1.1359 - categorical_accuracy: 0.6464 - val_loss: 1.1547 - val_categorical_accuracy: 0.6230\n",
      "Epoch 22/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.1373 - categorical_accuracy: 0.6441 - val_loss: 1.1294 - val_categorical_accuracy: 0.6369\n",
      "Epoch 23/100\n",
      "627/627 [==============================] - 23s 37ms/step - loss: 1.1301 - categorical_accuracy: 0.6455 - val_loss: 1.1372 - val_categorical_accuracy: 0.6311\n",
      "Epoch 24/100\n",
      "627/627 [==============================] - 23s 37ms/step - loss: 1.1227 - categorical_accuracy: 0.6512 - val_loss: 1.1965 - val_categorical_accuracy: 0.6136\n",
      "Epoch 25/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.1140 - categorical_accuracy: 0.6522 - val_loss: 1.1418 - val_categorical_accuracy: 0.6333\n",
      "Epoch 26/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.1001 - categorical_accuracy: 0.6573 - val_loss: 1.1451 - val_categorical_accuracy: 0.6288\n",
      "Epoch 27/100\n",
      "627/627 [==============================] - 23s 37ms/step - loss: 1.0937 - categorical_accuracy: 0.6607 - val_loss: 1.1006 - val_categorical_accuracy: 0.6436\n",
      "Epoch 28/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.0909 - categorical_accuracy: 0.6609 - val_loss: 1.1058 - val_categorical_accuracy: 0.6405\n",
      "Epoch 29/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.0754 - categorical_accuracy: 0.6646 - val_loss: 1.1386 - val_categorical_accuracy: 0.6320\n",
      "Epoch 30/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.0589 - categorical_accuracy: 0.6728 - val_loss: 1.1565 - val_categorical_accuracy: 0.6221\n",
      "Epoch 31/100\n",
      "627/627 [==============================] - 24s 38ms/step - loss: 1.0608 - categorical_accuracy: 0.6678 - val_loss: 1.0896 - val_categorical_accuracy: 0.6539\n",
      "Epoch 32/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.0477 - categorical_accuracy: 0.6779 - val_loss: 1.1491 - val_categorical_accuracy: 0.6333\n",
      "Epoch 33/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 1.0319 - categorical_accuracy: 0.6812 - val_loss: 1.1419 - val_categorical_accuracy: 0.6369\n",
      "Epoch 34/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 1.0319 - categorical_accuracy: 0.6748 - val_loss: 1.1250 - val_categorical_accuracy: 0.6387\n",
      "Epoch 35/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.0144 - categorical_accuracy: 0.6810 - val_loss: 1.1347 - val_categorical_accuracy: 0.6351\n",
      "Epoch 36/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 1.0078 - categorical_accuracy: 0.6863 - val_loss: 1.0766 - val_categorical_accuracy: 0.6580\n",
      "Epoch 37/100\n",
      "627/627 [==============================] - 24s 38ms/step - loss: 0.9982 - categorical_accuracy: 0.6900 - val_loss: 1.1190 - val_categorical_accuracy: 0.6517\n",
      "Epoch 38/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.9761 - categorical_accuracy: 0.6962 - val_loss: 1.2789 - val_categorical_accuracy: 0.6082\n",
      "Epoch 39/100\n",
      "627/627 [==============================] - 23s 37ms/step - loss: 0.9719 - categorical_accuracy: 0.6986 - val_loss: 1.0731 - val_categorical_accuracy: 0.6679\n",
      "Epoch 40/100\n",
      "627/627 [==============================] - 24s 38ms/step - loss: 0.9485 - categorical_accuracy: 0.7039 - val_loss: 1.1212 - val_categorical_accuracy: 0.6441\n",
      "Epoch 41/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.9533 - categorical_accuracy: 0.6998 - val_loss: 1.1102 - val_categorical_accuracy: 0.6495\n",
      "Epoch 42/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 0.9264 - categorical_accuracy: 0.7166 - val_loss: 1.1443 - val_categorical_accuracy: 0.6432\n",
      "Epoch 43/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.9140 - categorical_accuracy: 0.7137 - val_loss: 1.1330 - val_categorical_accuracy: 0.6391\n",
      "Epoch 44/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 0.9057 - categorical_accuracy: 0.7147 - val_loss: 1.1253 - val_categorical_accuracy: 0.6427\n",
      "Epoch 45/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 0.8907 - categorical_accuracy: 0.7244 - val_loss: 1.1161 - val_categorical_accuracy: 0.6544\n",
      "Epoch 46/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.8716 - categorical_accuracy: 0.7310 - val_loss: 1.1136 - val_categorical_accuracy: 0.6598\n",
      "Epoch 47/100\n",
      "627/627 [==============================] - 24s 38ms/step - loss: 0.8584 - categorical_accuracy: 0.7342 - val_loss: 1.0706 - val_categorical_accuracy: 0.6706\n",
      "Epoch 48/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 0.8517 - categorical_accuracy: 0.7345 - val_loss: 1.0979 - val_categorical_accuracy: 0.6625\n",
      "Epoch 49/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.8345 - categorical_accuracy: 0.7385 - val_loss: 1.1431 - val_categorical_accuracy: 0.6602\n",
      "Epoch 50/100\n",
      "627/627 [==============================] - 23s 37ms/step - loss: 0.8278 - categorical_accuracy: 0.7436 - val_loss: 1.0686 - val_categorical_accuracy: 0.6773\n",
      "Epoch 51/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 0.8024 - categorical_accuracy: 0.7521 - val_loss: 1.2154 - val_categorical_accuracy: 0.6207\n",
      "Epoch 52/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.7959 - categorical_accuracy: 0.7531 - val_loss: 1.1662 - val_categorical_accuracy: 0.6575\n",
      "Epoch 53/100\n",
      "627/627 [==============================] - 24s 38ms/step - loss: 0.7838 - categorical_accuracy: 0.7590 - val_loss: 1.1076 - val_categorical_accuracy: 0.6611\n",
      "Epoch 54/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.7666 - categorical_accuracy: 0.7644 - val_loss: 1.1999 - val_categorical_accuracy: 0.6445\n",
      "Epoch 55/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.7501 - categorical_accuracy: 0.7683 - val_loss: 1.1103 - val_categorical_accuracy: 0.6710\n",
      "Epoch 56/100\n",
      "627/627 [==============================] - 24s 38ms/step - loss: 0.7441 - categorical_accuracy: 0.7676 - val_loss: 1.0742 - val_categorical_accuracy: 0.6890\n",
      "Epoch 57/100\n",
      "627/627 [==============================] - 23s 36ms/step - loss: 0.7207 - categorical_accuracy: 0.7799 - val_loss: 1.1555 - val_categorical_accuracy: 0.6625\n",
      "Epoch 58/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.7180 - categorical_accuracy: 0.7797 - val_loss: 1.1758 - val_categorical_accuracy: 0.6679\n",
      "Epoch 59/100\n",
      "627/627 [==============================] - 22s 36ms/step - loss: 0.7003 - categorical_accuracy: 0.7843 - val_loss: 1.1003 - val_categorical_accuracy: 0.6746\n",
      "Epoch 60/100\n",
      "627/627 [==============================] - 22s 35ms/step - loss: 0.6845 - categorical_accuracy: 0.7898 - val_loss: 1.1746 - val_categorical_accuracy: 0.6683\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with strategy.scope():\n",
    "#     history = model.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_valid, y_valid), callbacks = callbacks)\n",
    "with tf.device('/device:GPU:0'):\n",
    "    history = model.fit(dataset,\n",
    "                        epochs=100,\n",
    "                        validation_data=valid_dataset,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 158, 118, 1024)    28672     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 158, 118, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 79, 59, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 79, 59, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 77, 57, 512)       4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 77, 57, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 38, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 38, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 36, 26, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 36, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 18, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 18, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 59904)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               15335680  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 21,274,122\n",
      "Trainable params: 21,270,026\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 158, 118, 1024)    28672     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 158, 118, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 79, 59, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 79, 59, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 77, 57, 512)       4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 77, 57, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 38, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 38, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 36, 26, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 36, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 18, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 18, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 59904)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               15335680  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 21,274,122\n",
      "Trainable params: 21,270,026\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "      2/Unknown - 1s 311ms/step - loss: 1.4360 - categorical_accuracy: 0.5781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2140s vs `on_train_batch_end` time: 0.4077s). Check your callbacks.\n",
      "627/627 [==============================] - 435s 694ms/step - loss: 1.2523 - categorical_accuracy: 0.6228 - val_loss: 1.2574 - val_categorical_accuracy: 0.5938\n",
      "Epoch 2/30\n",
      "627/627 [==============================] - ETA: 0s - loss: 1.2151 - categorical_accuracy: 0.6312\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "627/627 [==============================] - 434s 691ms/step - loss: 1.2151 - categorical_accuracy: 0.6312 - val_loss: 1.2580 - val_categorical_accuracy: 0.5848\n",
      "Epoch 3/30\n",
      "627/627 [==============================] - 435s 693ms/step - loss: 1.1753 - categorical_accuracy: 0.6411 - val_loss: 1.1448 - val_categorical_accuracy: 0.6329\n",
      "Epoch 4/30\n",
      "627/627 [==============================] - ETA: 0s - loss: 1.1556 - categorical_accuracy: 0.6456\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "627/627 [==============================] - 433s 691ms/step - loss: 1.1556 - categorical_accuracy: 0.6456 - val_loss: 1.2168 - val_categorical_accuracy: 0.5871\n",
      "Epoch 5/30\n",
      "  7/627 [..............................] - ETA: 5:57 - loss: 1.1974 - categorical_accuracy: 0.5982"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-19cea930359d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                         callbacks = callbacks)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# with strategy.scope():\n",
    "with tf.device('/device:GPU:0'):  \n",
    "    baseCNN = load_model(\"clothes_color_base_CNN_model.h5\")\n",
    "    baseCNN.summary()\n",
    "\n",
    "earlystop = EarlyStopping(patience=5)\n",
    "learning_rate_reduction=ReduceLROnPlateau(\n",
    "                        monitor= \"val_loss\", \n",
    "                        patience = 1, \n",
    "                        factor = 0.8, \n",
    "                        min_lr=1e-7,\n",
    "                        verbose=1)\n",
    "\n",
    "model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장    \n",
    "        filepath=\"./clothes_color_base_CNN_model.h5\", #모델 파일 경로\n",
    "        monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "        save_best_only=True)\n",
    "\n",
    "# print(#################################################################################)   \n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]\n",
    "\n",
    "for layer in baseCNN.layers:\n",
    "    layer.trainable = True\n",
    " \n",
    "# with strategy.scope(): \n",
    "with tf.device('/device:GPU:0'):  \n",
    "    model = baseCNN\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.0001),\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    history = model.fit(dataset,\n",
    "                        epochs=30,\n",
    "                        validation_data=valid_dataset,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 2,236,682\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "      2/Unknown - 0s 96ms/step - loss: 2.6428 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0465s vs `on_train_batch_end` time: 0.1446s). Check your callbacks.\n",
      "627/627 [==============================] - 138s 219ms/step - loss: 1.3665 - accuracy: 0.5452 - val_loss: 6.5762 - val_accuracy: 0.1535\n",
      "Epoch 2/10\n",
      "627/627 [==============================] - 136s 217ms/step - loss: 1.0160 - accuracy: 0.6651 - val_loss: 4.1767 - val_accuracy: 0.1777\n",
      "Epoch 3/10\n",
      "627/627 [==============================] - 136s 217ms/step - loss: 0.8719 - accuracy: 0.7124 - val_loss: 3.7843 - val_accuracy: 0.1957\n",
      "Epoch 4/10\n",
      "627/627 [==============================] - 137s 218ms/step - loss: 0.7595 - accuracy: 0.7451 - val_loss: 2.4392 - val_accuracy: 0.3164\n",
      "Epoch 5/10\n",
      "627/627 [==============================] - 137s 219ms/step - loss: 0.6473 - accuracy: 0.7858 - val_loss: 1.7542 - val_accuracy: 0.4847\n",
      "Epoch 6/10\n",
      "627/627 [==============================] - 137s 218ms/step - loss: 0.5523 - accuracy: 0.8187 - val_loss: 1.8781 - val_accuracy: 0.4785\n",
      "Epoch 7/10\n",
      "627/627 [==============================] - 137s 219ms/step - loss: 0.4712 - accuracy: 0.8437 - val_loss: 1.1192 - val_accuracy: 0.6620\n",
      "Epoch 8/10\n",
      "627/627 [==============================] - 137s 219ms/step - loss: 0.4057 - accuracy: 0.8642 - val_loss: 1.9488 - val_accuracy: 0.4874\n",
      "Epoch 9/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.8888\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "627/627 [==============================] - 137s 219ms/step - loss: 0.3395 - accuracy: 0.8888 - val_loss: 1.3450 - val_accuracy: 0.6517\n",
      "Epoch 10/10\n",
      "627/627 [==============================] - 137s 218ms/step - loss: 0.2356 - accuracy: 0.9252 - val_loss: 1.1893 - val_accuracy: 0.7002\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications import MobileNetV2 \n",
    "\n",
    "mobilenetV2 = MobileNetV2(weights ='imagenet', include_top = False, \n",
    "                              input_shape = (224, 224, 3), classifier_activation='softmax')\n",
    "\n",
    "earlystop = EarlyStopping(patience=5)\n",
    "learning_rate_reduction=ReduceLROnPlateau(\n",
    "                        monitor= \"val_loss\", \n",
    "                        patience = 2, \n",
    "                        factor = 0.5, \n",
    "                        min_lr=1e-7,\n",
    "                        verbose=1)\n",
    "\n",
    "model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장    \n",
    "        filepath=\"clothes_color_mobilenetV2.h5\", #모델 파일 경로\n",
    "        monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "        save_best_only=True)\n",
    "\n",
    "# print(mobilenetV2.summary())    \n",
    "# print(#################################################################################)   \n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]\n",
    "\n",
    "for layer in mobilenetV2.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "\n",
    "with tf.device('/device:GPU:0'):  \n",
    "    model = models.Sequential()\n",
    "    model.add(mobilenetV2)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(10, activation='softmax')) \n",
    "    model.summary()\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(10, activation='softmax')) \n",
    "#     model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(dataset,\n",
    "                        epochs=10,\n",
    "                        validation_data=valid_dataset,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 2,236,682\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 2,236,682\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "      2/Unknown - 0s 101ms/step - loss: 0.3044 - categorical_accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0532s vs `on_train_batch_end` time: 0.1481s). Check your callbacks.\n",
      "627/627 [==============================] - 130s 208ms/step - loss: 0.3339 - categorical_accuracy: 0.8910 - val_loss: 1.1096 - val_categorical_accuracy: 0.6939\n",
      "Epoch 2/10\n",
      "627/627 [==============================] - 130s 207ms/step - loss: 0.2743 - categorical_accuracy: 0.9118 - val_loss: 1.0908 - val_categorical_accuracy: 0.7217\n",
      "Epoch 3/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.2457 - categorical_accuracy: 0.9207\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "627/627 [==============================] - 130s 207ms/step - loss: 0.2457 - categorical_accuracy: 0.9207 - val_loss: 1.1271 - val_categorical_accuracy: 0.7181\n",
      "Epoch 4/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1996 - categorical_accuracy: 0.9376\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.199999919161201e-05.\n",
      "627/627 [==============================] - 130s 207ms/step - loss: 0.1996 - categorical_accuracy: 0.9376 - val_loss: 1.1882 - val_categorical_accuracy: 0.7226\n",
      "Epoch 5/10\n",
      "627/627 [==============================] - 130s 207ms/step - loss: 0.1642 - categorical_accuracy: 0.9502 - val_loss: 1.0897 - val_categorical_accuracy: 0.7428\n",
      "Epoch 6/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1550 - categorical_accuracy: 0.9521\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.5599999935366215e-05.\n",
      "627/627 [==============================] - 130s 207ms/step - loss: 0.1550 - categorical_accuracy: 0.9521 - val_loss: 1.1214 - val_categorical_accuracy: 0.7419\n",
      "Epoch 7/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1312 - categorical_accuracy: 0.9603\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.0480000239331277e-05.\n",
      "627/627 [==============================] - 130s 207ms/step - loss: 0.1312 - categorical_accuracy: 0.9603 - val_loss: 1.1617 - val_categorical_accuracy: 0.7424\n",
      "Epoch 8/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1139 - categorical_accuracy: 0.9666\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.6383999900426718e-05.\n",
      "627/627 [==============================] - 130s 207ms/step - loss: 0.1139 - categorical_accuracy: 0.9666 - val_loss: 1.1711 - val_categorical_accuracy: 0.7460\n",
      "Epoch 9/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1052 - categorical_accuracy: 0.9678\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.3107199629303068e-05.\n",
      "627/627 [==============================] - 129s 206ms/step - loss: 0.1052 - categorical_accuracy: 0.9678 - val_loss: 1.1487 - val_categorical_accuracy: 0.7482\n",
      "Epoch 10/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.0917 - categorical_accuracy: 0.9741\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.048575941240415e-05.\n",
      "627/627 [==============================] - 130s 207ms/step - loss: 0.0917 - categorical_accuracy: 0.9741 - val_loss: 1.1878 - val_categorical_accuracy: 0.7478\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# with strategy.scope():\n",
    "with tf.device('/device:GPU:0'):  \n",
    "    mobilenetV2_load = load_model(\"clothes_color_mobilenetV2.h5\")\n",
    "    mobilenetV2_load.summary()\n",
    "\n",
    "earlystop = EarlyStopping(patience=5)\n",
    "learning_rate_reduction=ReduceLROnPlateau(\n",
    "                        monitor= \"val_loss\", \n",
    "                        patience = 1, \n",
    "                        factor = 0.8, \n",
    "                        min_lr=1e-7,\n",
    "                        verbose=1)\n",
    "\n",
    "model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장    \n",
    "        filepath=\"./clothes_color_mobilenetV2.h5\", #모델 파일 경로\n",
    "        monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "        save_best_only=True)\n",
    "\n",
    "# print(#################################################################################)   \n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]\n",
    "\n",
    "for layer in mobilenetV2_load.layers:\n",
    "    layer.trainable = True\n",
    " \n",
    "# with strategy.scope(): \n",
    "with tf.device('/device:GPU:0'):  \n",
    "    model = mobilenetV2_load\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.00005),\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    history = model.fit(dataset,\n",
    "                        epochs=10,\n",
    "                        validation_data=valid_dataset,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 5, 3, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                19210     \n",
      "=================================================================\n",
      "Total params: 18,341,194\n",
      "Trainable params: 18,112,138\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "627/627 [==============================] - 153s 244ms/step - loss: 1.1823 - accuracy: 0.6231 - val_loss: 1.0662 - val_accuracy: 0.6643\n",
      "Epoch 2/30\n",
      "627/627 [==============================] - 147s 235ms/step - loss: 0.8489 - accuracy: 0.7237 - val_loss: 1.0249 - val_accuracy: 0.6822\n",
      "Epoch 3/30\n",
      "627/627 [==============================] - 147s 234ms/step - loss: 0.6359 - accuracy: 0.7932 - val_loss: 1.0076 - val_accuracy: 0.6939\n",
      "Epoch 4/30\n",
      "627/627 [==============================] - 147s 235ms/step - loss: 0.4838 - accuracy: 0.8446 - val_loss: 0.9647 - val_accuracy: 0.7280\n",
      "Epoch 5/30\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8872\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 5.600000149570406e-05.\n",
      "627/627 [==============================] - 145s 232ms/step - loss: 0.3605 - accuracy: 0.8872 - val_loss: 0.9826 - val_accuracy: 0.7163\n",
      "Epoch 6/30\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9272\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.4800000614486636e-05.\n",
      "627/627 [==============================] - 146s 233ms/step - loss: 0.2449 - accuracy: 0.9272 - val_loss: 0.9717 - val_accuracy: 0.7415\n",
      "Epoch 7/30\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9523\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.583999932743609e-05.\n",
      "627/627 [==============================] - 145s 232ms/step - loss: 0.1713 - accuracy: 0.9523 - val_loss: 1.0123 - val_accuracy: 0.7496\n",
      "Epoch 8/30\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9717\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8671999461948872e-05.\n",
      "627/627 [==============================] - 145s 231ms/step - loss: 0.1054 - accuracy: 0.9717 - val_loss: 0.9838 - val_accuracy: 0.7608\n",
      "Epoch 9/30\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9821\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.293759898748249e-05.\n",
      "627/627 [==============================] - 145s 232ms/step - loss: 0.0751 - accuracy: 0.9821 - val_loss: 1.0172 - val_accuracy: 0.7594\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications import DenseNet201 \n",
    "\n",
    "densenet201 = DenseNet201(weights ='imagenet', include_top = False, input_shape=(160,120,3))\n",
    "\n",
    "earlystop = EarlyStopping(patience=5)\n",
    "learning_rate_reduction=ReduceLROnPlateau(\n",
    "                        monitor= \"val_loss\", \n",
    "                        patience = 1, \n",
    "                        factor = 0.8, \n",
    "                        min_lr=1e-7,\n",
    "                        verbose=1)\n",
    "\n",
    "model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장    \n",
    "        filepath=\"./clothes_color_densenet201_crop.h5\", #모델 파일 경로\n",
    "        monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "        save_best_only=True)\n",
    "\n",
    "# print(#################################################################################)   \n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]\n",
    "\n",
    "for layer in densenet201.layers:\n",
    "    layer.trainable = True\n",
    " \n",
    "# with strategy.scope(): \n",
    "with tf.device('/device:GPU:0'):  \n",
    "    model = models.Sequential()\n",
    "    model.add(densenet201)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(10, activation='softmax')) \n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.00007),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(dataset,\n",
    "                        epochs=30,\n",
    "                        validation_data=valid_dataset,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 5, 3, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                19210     \n",
      "=================================================================\n",
      "Total params: 18,341,194\n",
      "Trainable params: 18,112,138\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 5, 3, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                19210     \n",
      "=================================================================\n",
      "Total params: 18,341,194\n",
      "Trainable params: 18,112,138\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "627/627 [==============================] - 148s 235ms/step - loss: 0.3255 - categorical_accuracy: 0.9006 - val_loss: 0.9471 - val_categorical_accuracy: 0.7491\n",
      "Epoch 2/10\n",
      "627/627 [==============================] - 147s 234ms/step - loss: 0.2427 - categorical_accuracy: 0.9278 - val_loss: 0.9404 - val_categorical_accuracy: 0.7482\n",
      "Epoch 3/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1773 - categorical_accuracy: 0.9483\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-05.\n",
      "627/627 [==============================] - 145s 232ms/step - loss: 0.1773 - categorical_accuracy: 0.9483 - val_loss: 1.0324 - val_categorical_accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1331 - categorical_accuracy: 0.9630\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.050000061397441e-05.\n",
      "627/627 [==============================] - 145s 231ms/step - loss: 0.1331 - categorical_accuracy: 0.9630 - val_loss: 1.0578 - val_categorical_accuracy: 0.7608\n",
      "Epoch 5/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.1013 - categorical_accuracy: 0.9724\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.6449999242904596e-05.\n",
      "627/627 [==============================] - 145s 231ms/step - loss: 0.1013 - categorical_accuracy: 0.9724 - val_loss: 1.0753 - val_categorical_accuracy: 0.7518\n",
      "Epoch 6/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.0767 - categorical_accuracy: 0.9798\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.28050009557046e-05.\n",
      "627/627 [==============================] - 145s 231ms/step - loss: 0.0767 - categorical_accuracy: 0.9798 - val_loss: 1.0581 - val_categorical_accuracy: 0.7657\n",
      "Epoch 7/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.0572 - categorical_accuracy: 0.9854\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.952450086013414e-05.\n",
      "627/627 [==============================] - 145s 231ms/step - loss: 0.0572 - categorical_accuracy: 0.9854 - val_loss: 1.1210 - val_categorical_accuracy: 0.7397\n",
      "Epoch 8/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.0492 - categorical_accuracy: 0.9871\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.6572050774120726e-05.\n",
      "627/627 [==============================] - 145s 231ms/step - loss: 0.0492 - categorical_accuracy: 0.9871 - val_loss: 1.0979 - val_categorical_accuracy: 0.7621\n",
      "Epoch 9/10\n",
      "627/627 [==============================] - ETA: 0s - loss: 0.0410 - categorical_accuracy: 0.9890\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.3914845041872467e-05.\n",
      "627/627 [==============================] - 146s 233ms/step - loss: 0.0410 - categorical_accuracy: 0.9890 - val_loss: 1.1929 - val_categorical_accuracy: 0.7563\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# with strategy.scope():\n",
    "with tf.device('/device:GPU:0'):  \n",
    "    densenet201_load = load_model(\"clothes_color_densenet201_crop.h5\")\n",
    "    densenet201_load.summary()\n",
    "\n",
    "earlystop = EarlyStopping(patience=7)\n",
    "learning_rate_reduction=ReduceLROnPlateau(\n",
    "                        monitor= \"val_loss\", \n",
    "                        patience = 1, \n",
    "                        factor = 0.9, \n",
    "                        min_lr=1e-7,\n",
    "                        verbose=1)\n",
    "\n",
    "model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장    \n",
    "        filepath=\"./clothes_color_densenet201_crop.h5\", #모델 파일 경로\n",
    "        monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "        save_best_only=True)\n",
    "\n",
    "# print(#################################################################################)   \n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]\n",
    "\n",
    "for layer in densenet201_load.layers:\n",
    "    layer.trainable = True\n",
    " \n",
    "# with strategy.scope(): \n",
    "with tf.device('/device:GPU:0'):  \n",
    "    model = densenet201_load\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.00005),\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    history = model.fit(dataset,\n",
    "                        epochs=10,\n",
    "                        validation_data=valid_dataset,\n",
    "                        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnetb5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 300, 300, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 300, 300, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 301, 301, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 150, 150, 48) 1296        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 150, 150, 48) 192         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 150, 150, 48) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 150, 150, 48) 432         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 150, 150, 48) 192         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 150, 150, 48) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 48)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 12)     588         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 48)     624         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 150, 150, 48) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 150, 150, 24) 1152        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 150, 150, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 150, 150, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 150, 150, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 150, 150, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 150, 150, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 150, 150, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 150, 150, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 150, 150, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 150, 150, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_dwconv (DepthwiseConv2D (None, 150, 150, 24) 216         block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1c_bn (BatchNormalization) (None, 150, 150, 24) 96          block1c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1c_activation (Activation) (None, 150, 150, 24) 0           block1c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_squeeze (GlobalAvera (None, 24)           0           block1c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_excite (Multiply)    (None, 150, 150, 24) 0           block1c_activation[0][0]         \n",
      "                                                                 block1c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_conv (Conv2D)   (None, 150, 150, 24) 576         block1c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_bn (BatchNormal (None, 150, 150, 24) 96          block1c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1c_drop (Dropout)          (None, 150, 150, 24) 0           block1c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_add (Add)               (None, 150, 150, 24) 0           block1c_drop[0][0]               \n",
      "                                                                 block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 150, 150, 144 3456        block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 150, 150, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 150, 150, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 151, 151, 144 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 75, 75, 144)  1296        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 75, 75, 144)  576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 75, 75, 144)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 75, 75, 144)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 75, 75, 40)   5760        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 75, 75, 40)   160         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 75, 75, 240)  9600        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 75, 75, 240)  960         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 75, 75, 240)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 75, 75, 240)  2160        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 75, 75, 240)  960         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 75, 75, 240)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 240)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 75, 75, 240)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 75, 75, 40)   9600        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 75, 75, 40)   160         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 75, 75, 40)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 75, 75, 40)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 75, 75, 240)  9600        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 75, 75, 240)  960         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 75, 75, 240)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 75, 75, 240)  2160        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 75, 75, 240)  960         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 75, 75, 240)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 240)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 75, 75, 240)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 75, 75, 40)   9600        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 75, 75, 40)   160         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 75, 75, 40)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 75, 75, 40)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 75, 75, 240)  9600        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 75, 75, 240)  960         block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 75, 75, 240)  0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 75, 75, 240)  2160        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 75, 75, 240)  960         block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 75, 75, 240)  0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 240)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 75, 75, 240)  0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 75, 75, 40)   9600        block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 75, 75, 40)   160         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (Dropout)          (None, 75, 75, 40)   0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 75, 75, 40)   0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_conv (Conv2D)    (None, 75, 75, 240)  9600        block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_bn (BatchNormali (None, 75, 75, 240)  960         block2e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_activation (Acti (None, 75, 75, 240)  0           block2e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_dwconv (DepthwiseConv2D (None, 75, 75, 240)  2160        block2e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2e_bn (BatchNormalization) (None, 75, 75, 240)  960         block2e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2e_activation (Activation) (None, 75, 75, 240)  0           block2e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_squeeze (GlobalAvera (None, 240)          0           block2e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reshape (Reshape)    (None, 1, 1, 240)    0           block2e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block2e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block2e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_excite (Multiply)    (None, 75, 75, 240)  0           block2e_activation[0][0]         \n",
      "                                                                 block2e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_conv (Conv2D)   (None, 75, 75, 40)   9600        block2e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_bn (BatchNormal (None, 75, 75, 40)   160         block2e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2e_drop (Dropout)          (None, 75, 75, 40)   0           block2e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_add (Add)               (None, 75, 75, 40)   0           block2e_drop[0][0]               \n",
      "                                                                 block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 75, 75, 240)  9600        block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 75, 75, 240)  960         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 75, 75, 240)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 79, 79, 240)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 38, 38, 240)  6000        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 38, 38, 240)  960         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 38, 38, 240)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 240)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 38, 38, 240)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 38, 38, 64)   15360       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 38, 38, 64)   256         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 38, 38, 384)  24576       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 38, 38, 384)  1536        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 38, 38, 384)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 38, 38, 384)  9600        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 38, 38, 384)  1536        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 38, 38, 384)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 384)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 38, 38, 384)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 38, 38, 64)   24576       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 38, 38, 64)   256         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 38, 38, 64)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 38, 38, 64)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 38, 38, 384)  24576       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 38, 38, 384)  1536        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 38, 38, 384)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 38, 38, 384)  9600        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 38, 38, 384)  1536        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 38, 38, 384)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 384)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 38, 38, 384)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 38, 38, 64)   24576       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 38, 38, 64)   256         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 38, 38, 64)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 38, 38, 64)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 38, 38, 384)  24576       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 38, 38, 384)  1536        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 38, 38, 384)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 38, 38, 384)  9600        block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 38, 38, 384)  1536        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 38, 38, 384)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 384)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 38, 38, 384)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 38, 38, 64)   24576       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 38, 38, 64)   256         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (Dropout)          (None, 38, 38, 64)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 38, 38, 64)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_conv (Conv2D)    (None, 38, 38, 384)  24576       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_bn (BatchNormali (None, 38, 38, 384)  1536        block3e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_activation (Acti (None, 38, 38, 384)  0           block3e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_dwconv (DepthwiseConv2D (None, 38, 38, 384)  9600        block3e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3e_bn (BatchNormalization) (None, 38, 38, 384)  1536        block3e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3e_activation (Activation) (None, 38, 38, 384)  0           block3e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_squeeze (GlobalAvera (None, 384)          0           block3e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reshape (Reshape)    (None, 1, 1, 384)    0           block3e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block3e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block3e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_excite (Multiply)    (None, 38, 38, 384)  0           block3e_activation[0][0]         \n",
      "                                                                 block3e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_conv (Conv2D)   (None, 38, 38, 64)   24576       block3e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_bn (BatchNormal (None, 38, 38, 64)   256         block3e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3e_drop (Dropout)          (None, 38, 38, 64)   0           block3e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_add (Add)               (None, 38, 38, 64)   0           block3e_drop[0][0]               \n",
      "                                                                 block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 38, 38, 384)  24576       block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 38, 38, 384)  1536        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 38, 38, 384)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 39, 39, 384)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 19, 19, 384)  3456        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 19, 19, 384)  1536        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 19, 19, 384)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 384)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 384)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 16)     6160        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 384)    6528        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 19, 19, 384)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 19, 19, 128)  49152       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 19, 19, 128)  512         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 19, 19, 768)  98304       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 19, 19, 768)  3072        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 19, 19, 768)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 19, 19, 768)  6912        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 19, 19, 768)  3072        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 19, 19, 768)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 768)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 19, 19, 768)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 19, 19, 128)  98304       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 19, 19, 128)  512         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 19, 19, 128)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 19, 19, 128)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 19, 19, 768)  98304       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 19, 19, 768)  3072        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 19, 19, 768)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 19, 19, 768)  6912        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 19, 19, 768)  3072        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 19, 19, 768)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 768)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 19, 19, 768)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 19, 19, 128)  98304       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 19, 19, 128)  512         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 19, 19, 128)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 19, 19, 128)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 19, 19, 768)  98304       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 19, 19, 768)  3072        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 19, 19, 768)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 19, 19, 768)  6912        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 19, 19, 768)  3072        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 19, 19, 768)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 768)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 19, 19, 768)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 19, 19, 128)  98304       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 19, 19, 128)  512         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 19, 19, 128)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 19, 19, 128)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 19, 19, 768)  98304       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 19, 19, 768)  3072        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 19, 19, 768)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 19, 19, 768)  6912        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 19, 19, 768)  3072        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 19, 19, 768)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 768)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 19, 19, 768)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 19, 19, 128)  98304       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 19, 19, 128)  512         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 19, 19, 128)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 19, 19, 128)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 19, 19, 768)  98304       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 19, 19, 768)  3072        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 19, 19, 768)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 19, 19, 768)  6912        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 19, 19, 768)  3072        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 19, 19, 768)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 768)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 19, 19, 768)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 19, 19, 128)  98304       block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 19, 19, 128)  512         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (Dropout)          (None, 19, 19, 128)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 19, 19, 128)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_conv (Conv2D)    (None, 19, 19, 768)  98304       block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_bn (BatchNormali (None, 19, 19, 768)  3072        block4g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_activation (Acti (None, 19, 19, 768)  0           block4g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_dwconv (DepthwiseConv2D (None, 19, 19, 768)  6912        block4g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4g_bn (BatchNormalization) (None, 19, 19, 768)  3072        block4g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4g_activation (Activation) (None, 19, 19, 768)  0           block4g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_squeeze (GlobalAvera (None, 768)          0           block4g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reshape (Reshape)    (None, 1, 1, 768)    0           block4g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block4g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block4g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_excite (Multiply)    (None, 19, 19, 768)  0           block4g_activation[0][0]         \n",
      "                                                                 block4g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_conv (Conv2D)   (None, 19, 19, 128)  98304       block4g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_bn (BatchNormal (None, 19, 19, 128)  512         block4g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4g_drop (Dropout)          (None, 19, 19, 128)  0           block4g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_add (Add)               (None, 19, 19, 128)  0           block4g_drop[0][0]               \n",
      "                                                                 block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 19, 19, 768)  98304       block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 19, 19, 768)  3072        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 19, 19, 768)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 19, 19, 768)  19200       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 19, 19, 768)  3072        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 19, 19, 768)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 768)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 768)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 32)     24608       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 768)    25344       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 19, 19, 768)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 19, 19, 176)  135168      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 19, 19, 176)  704         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 19, 19, 1056) 185856      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 19, 19, 1056) 4224        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 19, 19, 1056) 0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 19, 19, 1056) 26400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 19, 19, 1056) 4224        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 19, 19, 1056) 0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 1056)         0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 19, 19, 1056) 0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 19, 19, 176)  185856      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 19, 19, 176)  704         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 19, 19, 176)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 19, 19, 176)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 19, 19, 1056) 185856      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 19, 19, 1056) 4224        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 19, 19, 1056) 0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 19, 19, 1056) 26400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 19, 19, 1056) 4224        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 19, 19, 1056) 0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 1056)         0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 19, 19, 1056) 0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 19, 19, 176)  185856      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 19, 19, 176)  704         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 19, 19, 176)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 19, 19, 176)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 19, 19, 1056) 185856      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 19, 19, 1056) 4224        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 19, 19, 1056) 0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 19, 19, 1056) 26400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 19, 19, 1056) 4224        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 19, 19, 1056) 0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 1056)         0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 19, 19, 1056) 0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 19, 19, 176)  185856      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 19, 19, 176)  704         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 19, 19, 176)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 19, 19, 176)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 19, 19, 1056) 185856      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 19, 19, 1056) 4224        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 19, 19, 1056) 0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 19, 19, 1056) 26400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 19, 19, 1056) 4224        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 19, 19, 1056) 0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 1056)         0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 19, 19, 1056) 0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 19, 19, 176)  185856      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 19, 19, 176)  704         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 19, 19, 176)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 19, 19, 176)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 19, 19, 1056) 185856      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 19, 19, 1056) 4224        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 19, 19, 1056) 0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 19, 19, 1056) 26400       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 19, 19, 1056) 4224        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 19, 19, 1056) 0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 1056)         0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 19, 19, 1056) 0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 19, 19, 176)  185856      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 19, 19, 176)  704         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (Dropout)          (None, 19, 19, 176)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 19, 19, 176)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_conv (Conv2D)    (None, 19, 19, 1056) 185856      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_bn (BatchNormali (None, 19, 19, 1056) 4224        block5g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_activation (Acti (None, 19, 19, 1056) 0           block5g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_dwconv (DepthwiseConv2D (None, 19, 19, 1056) 26400       block5g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5g_bn (BatchNormalization) (None, 19, 19, 1056) 4224        block5g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5g_activation (Activation) (None, 19, 19, 1056) 0           block5g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_squeeze (GlobalAvera (None, 1056)         0           block5g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block5g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block5g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block5g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_excite (Multiply)    (None, 19, 19, 1056) 0           block5g_activation[0][0]         \n",
      "                                                                 block5g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_conv (Conv2D)   (None, 19, 19, 176)  185856      block5g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_bn (BatchNormal (None, 19, 19, 176)  704         block5g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5g_drop (Dropout)          (None, 19, 19, 176)  0           block5g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_add (Add)               (None, 19, 19, 176)  0           block5g_drop[0][0]               \n",
      "                                                                 block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 19, 19, 1056) 185856      block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 19, 19, 1056) 4224        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 19, 19, 1056) 0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 23, 23, 1056) 0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 10, 10, 1056) 26400       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 10, 10, 1056) 4224        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 10, 10, 1056) 0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 1056)         0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 1056)   0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 44)     46508       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 1056)   47520       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 10, 10, 1056) 0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 10, 10, 304)  321024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 10, 10, 1824) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 45600       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 10, 10, 1824) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1824)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 10, 10, 1824) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 10, 10, 304)  554496      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 10, 10, 304)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 10, 10, 304)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 10, 10, 1824) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 45600       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 10, 10, 1824) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1824)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 10, 10, 1824) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 10, 10, 304)  554496      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 10, 10, 304)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 10, 10, 304)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 10, 10, 1824) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 45600       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 10, 10, 1824) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1824)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 10, 10, 1824) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 10, 10, 304)  554496      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 10, 10, 304)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 10, 10, 304)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 10, 10, 1824) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 45600       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 10, 10, 1824) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1824)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 10, 10, 1824) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 10, 10, 304)  554496      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 10, 10, 304)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 10, 10, 304)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 10, 10, 1824) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 45600       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 10, 10, 1824) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1824)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 10, 10, 1824) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 10, 10, 304)  554496      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 10, 10, 304)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 10, 10, 304)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 10, 10, 1824) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 45600       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 10, 10, 1824) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 1824)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 10, 10, 1824) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 10, 10, 304)  554496      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (Dropout)          (None, 10, 10, 304)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 10, 10, 304)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 10, 10, 1824) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 45600       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 10, 10, 1824) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 1824)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 10, 10, 1824) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 10, 10, 304)  554496      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (Dropout)          (None, 10, 10, 304)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 10, 10, 304)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block6i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_activation (Acti (None, 10, 10, 1824) 0           block6i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 45600       block6i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6i_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block6i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6i_activation (Activation) (None, 10, 10, 1824) 0           block6i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_squeeze (GlobalAvera (None, 1824)         0           block6i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block6i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block6i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block6i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_excite (Multiply)    (None, 10, 10, 1824) 0           block6i_activation[0][0]         \n",
      "                                                                 block6i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_conv (Conv2D)   (None, 10, 10, 304)  554496      block6i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_bn (BatchNormal (None, 10, 10, 304)  1216        block6i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6i_drop (Dropout)          (None, 10, 10, 304)  0           block6i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_add (Add)               (None, 10, 10, 304)  0           block6i_drop[0][0]               \n",
      "                                                                 block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 10, 10, 1824) 554496      block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 10, 10, 1824) 7296        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 10, 10, 1824) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 10, 10, 1824) 16416       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 10, 10, 1824) 7296        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 10, 10, 1824) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1824)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1824)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 76)     138700      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1824)   140448      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 10, 10, 1824) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 10, 10, 512)  933888      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 10, 10, 512)  2048        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 10, 10, 3072) 1572864     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 10, 10, 3072) 12288       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 10, 10, 3072) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 10, 10, 3072) 27648       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 10, 10, 3072) 12288       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 10, 10, 3072) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 3072)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 3072)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 128)    393344      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 3072)   396288      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 10, 10, 3072) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 10, 10, 512)  1572864     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 10, 10, 512)  2048        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 10, 10, 512)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 10, 10, 512)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_conv (Conv2D)    (None, 10, 10, 3072) 1572864     block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_bn (BatchNormali (None, 10, 10, 3072) 12288       block7c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_activation (Acti (None, 10, 10, 3072) 0           block7c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_dwconv (DepthwiseConv2D (None, 10, 10, 3072) 27648       block7c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7c_bn (BatchNormalization) (None, 10, 10, 3072) 12288       block7c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7c_activation (Activation) (None, 10, 10, 3072) 0           block7c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_squeeze (GlobalAvera (None, 3072)         0           block7c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reshape (Reshape)    (None, 1, 1, 3072)   0           block7c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reduce (Conv2D)      (None, 1, 1, 128)    393344      block7c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_expand (Conv2D)      (None, 1, 1, 3072)   396288      block7c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_excite (Multiply)    (None, 10, 10, 3072) 0           block7c_activation[0][0]         \n",
      "                                                                 block7c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_conv (Conv2D)   (None, 10, 10, 512)  1572864     block7c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_bn (BatchNormal (None, 10, 10, 512)  2048        block7c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7c_drop (Dropout)          (None, 10, 10, 512)  0           block7c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_add (Add)               (None, 10, 10, 512)  0           block7c_drop[0][0]               \n",
      "                                                                 block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 10, 10, 2048) 1048576     block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 10, 10, 2048) 8192        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 10, 10, 2048) 0           top_bn[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 28,513,527\n",
      "Trainable params: 28,340,784\n",
      "Non-trainable params: 172,743\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb5 (Functional)  (None, 10, 10, 2048)      28513527  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 28,534,017\n",
      "Trainable params: 28,361,274\n",
      "Non-trainable params: 172,743\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "2005/2005 [==============================] - 1375s 686ms/step - loss: 1.2999 - categorical_accuracy: 0.5753 - val_loss: 2.1659 - val_categorical_accuracy: 0.3510\n",
      "Epoch 2/30\n",
      "2005/2005 [==============================] - 1386s 691ms/step - loss: 1.0546 - categorical_accuracy: 0.6592 - val_loss: 2.8518 - val_categorical_accuracy: 0.2487\n",
      "Epoch 3/30\n",
      "2005/2005 [==============================] - 1389s 693ms/step - loss: 0.9043 - categorical_accuracy: 0.7000 - val_loss: 1.3361 - val_categorical_accuracy: 0.5480\n",
      "Epoch 4/30\n",
      "2005/2005 [==============================] - 1390s 693ms/step - loss: 0.7484 - categorical_accuracy: 0.7544 - val_loss: 1.3392 - val_categorical_accuracy: 0.5785\n",
      "Epoch 5/30\n",
      "2005/2005 [==============================] - 1391s 694ms/step - loss: 0.6107 - categorical_accuracy: 0.7991 - val_loss: 1.4792 - val_categorical_accuracy: 0.5853\n",
      "Epoch 6/30\n",
      "2005/2005 [==============================] - ETA: 0s - loss: 0.5000 - categorical_accuracy: 0.8369\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.5000000934815034e-05.\n",
      "2005/2005 [==============================] - 1390s 693ms/step - loss: 0.5000 - categorical_accuracy: 0.8369 - val_loss: 3.6724 - val_categorical_accuracy: 0.2908\n",
      "Epoch 7/30\n",
      "2005/2005 [==============================] - 1395s 696ms/step - loss: 0.3361 - categorical_accuracy: 0.8922 - val_loss: 1.2069 - val_categorical_accuracy: 0.6732\n",
      "Epoch 8/30\n",
      "2005/2005 [==============================] - 1388s 692ms/step - loss: 0.2705 - categorical_accuracy: 0.9135 - val_loss: 1.3610 - val_categorical_accuracy: 0.6737\n",
      "Epoch 9/30\n",
      "2005/2005 [==============================] - 1386s 691ms/step - loss: 0.2276 - categorical_accuracy: 0.9278 - val_loss: 2.4171 - val_categorical_accuracy: 0.4708\n",
      "Epoch 10/30\n",
      "2005/2005 [==============================] - ETA: 0s - loss: 0.1925 - categorical_accuracy: 0.9391\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.7500000467407517e-05.\n",
      "2005/2005 [==============================] - 1385s 691ms/step - loss: 0.1925 - categorical_accuracy: 0.9391 - val_loss: 2.5313 - val_categorical_accuracy: 0.4933\n",
      "Epoch 11/30\n",
      " 404/2005 [=====>........................] - ETA: 18:02 - loss: 0.1646 - categorical_accuracy: 0.9495"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-368163f868f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     callbacks = callbacks)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.applications import EfficientNetB5 \n",
    "\n",
    "efficientnet = EfficientNetB5(weights ='imagenet', include_top = False, \n",
    "                              input_shape = (300, 300, 3))\n",
    "\n",
    "earlystop = EarlyStopping(patience=5)\n",
    "learning_rate_reduction=ReduceLROnPlateau(\n",
    "                        monitor= \"val_loss\", \n",
    "                        patience = 3, \n",
    "                        factor = 0.5, \n",
    "                        min_lr=1e-7,\n",
    "                        verbose=1)\n",
    "\n",
    "model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장    \n",
    "        filepath=\"./clothes_color_efficientnet.h5\", #모델 파일 경로\n",
    "        monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "        save_best_only=True)\n",
    "\n",
    "print(efficientnet.summary())    \n",
    "# print(#################################################################################)   \n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]\n",
    "\n",
    "for layer in efficientnet.layers:\n",
    "    layer.trainable = True\n",
    " \n",
    "with tf.device('/device:GPU:0'):  \n",
    "    model = models.Sequential()\n",
    "    model.add(efficientnet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(10, activation='softmax')) \n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=0.00007),\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    history = model.fit(dataset,\n",
    "                    epochs=30,\n",
    "                    validation_data=valid_dataset,\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 파일 TFrecord 생성 및 불러들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_test_tfrecords(id_list, test_id_list, tfrecords_name):\n",
    "    print(\"Start converting\")\n",
    "    options = tf.io.TFRecordOptions(compression_type = 'GZIP')\n",
    "    with tf.io.TFRecordWriter(path=pth.join(tfrecords_name+'.tfrecords'), options=options) as writer:\n",
    "        for id_, test_id in tqdm(zip(id_list, test_id_list), total=len(id_list), position=0, leave=True):\n",
    "            image_path = pth.join(path, id_)\n",
    "            _binary_image = tf.io.read_file(image_path)\n",
    "\n",
    "            string_set = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image_raw': _bytes_feature(_binary_image),\n",
    "                'id': _bytes_feature(test_id.encode()),\n",
    "            }))\n",
    "\n",
    "            writer.write(string_set.SerializeToString())    \n",
    "\n",
    "to_test_tfrecords(file_list,file_name_list, pth.join(path, 'tf_record_test'))\n",
    "\n",
    "test_tfrecord_path = path + '/tf_record_test.tfrecords'\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASS = 10\n",
    "img_size = (224,224) # <- 학습할때 썼던 이미지 사이즈 입력!\n",
    "\n",
    "image_feature_description_test = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'id': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_image_function_test(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description_test)\n",
    "\n",
    "def map_func_test(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = target_record['id']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def prep_func_test(image, label):\n",
    "    result_image = image / 255\n",
    "    result_image = tf.image.resize(result_image, img_size)\n",
    "\n",
    "    return result_image, label\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset(test_tfrecord_path, compression_type='GZIP')\n",
    "test_dataset = test_dataset.map(_parse_image_function_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(map_func_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.map(prep_func_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델불러오기 및 예측\n",
    "model = load_model('../clothes_color_densenet201_20201218.h5', compile=False)\n",
    "pred = model.predict(test_dataset)\n",
    "color_list = np.argmax(pred,axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest_p37] *",
   "language": "python",
   "name": "conda-env-pytorch_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
